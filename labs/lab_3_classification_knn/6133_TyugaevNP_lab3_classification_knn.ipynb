{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification KNN 6133 Тюгаев Никита Павлович"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Считать в `pandas.DataFrame` любой источник данных: CSV, JSON, Excel-файл, HTML-таблицу и т.п."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Бинарная классификация:\n",
    "   - Привести описание датасета.\n",
    "   - Осуществить предобработку данных (избавиться от `null`, убрать некоторые признаки и т.п.) - \"подчистить данные\".\n",
    "   - Закодировать категориальные признаки при необходимости.\n",
    "   - Выбрать какое-нибудь значение гиперпараметра $k$ алгоритма $kNN$.\n",
    "   - Разбить выборку на обучающую и тестовую.\n",
    "     > Разбиение использовать одно и то же для всех последующих манипуляций.\n",
    "   - Осуществить бинарную классификацию.\n",
    "   - Посчитать метрики: $accuracy$, $precision$, $recall$, $\\textit{f-measure}$, а также составить `classification_report`.\n",
    "   - Нормализовать данные (`StandardScaler`или `MinMaxScaler`).\n",
    "   - Осуществить бинарную классификацию.\n",
    "   - Посчитать метрики: $accuracy$, $precision$, $recall$, $\\textit{f-measure}$, а также составить `classification_report`.\n",
    "   - Сравнить метрики на данных без нормализации и с применением нормализации.\n",
    "     > Далее используем нормализованные данные.\n",
    "   - Построить `сorrelation heatmap` и/или воспользоваться методом `corr()`. Выбрать наиболее важные признаки эвристически или на основании каких-нибудь вычислений (***см. [примечание](#примечание)***).\n",
    "   - Осуществить бинарную классификацию с отфильтрованными признаками.\n",
    "   - Посчитать метрики: $accuracy$, $precision$, $recall$, $\\textit{f-measure}$, а также составить `classification_report`.\n",
    "   - Сравнить результаты \"до\" и \"после\" фильтрации, сделать выводы.\n",
    "     > Естественно, искомые результаты - улучшение метрик.\n",
    "   - Перебрать значения гиперпараметра $k$ в каком-нибудь диапазоне с использованием кросс-валидации на данных\n",
    "     > данных - исходных данных до разбиения с применением нормализации с отфильтрованными признаками. Построить график *train/test accuracy* в зависимости от значения $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Привести описание датасета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Осуществить предобработку данных (избавиться от `null`, убрать некоторые признаки и т.п.) - \"подчистить данные\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Закодировать категориальные признаки при необходимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Выбрать какое-нибудь значение гиперпараметра $k$ алгоритма $kNN$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Разбить выборку на обучающую и тестовую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Осуществить бинарную классификацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Посчитать метрики: $accuracy$, $precision$, $recall$, $\\textit{f-measure}$, а также составить `classification_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Нормализовать данные (`StandardScaler`или `MinMaxScaler`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Осуществить бинарную классификацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Посчитать метрики: $accuracy$, $precision$, $recall$, $\\textit{f-measure}$, а также составить `classification_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Сравнить метрики на данных без нормализации и с применением нормализации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Построить `сorrelation heatmap` и/или воспользоваться методом `corr()`. Выбрать наиболее важные признаки эвристически или на основании каких-нибудь вычислений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Осуществить бинарную классификацию с отфильтрованными признаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Посчитать метрики: $accuracy$, $precision$, $recall$, $\\textit{f-measure}$, а также составить `classification_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Сравнить результаты \"до\" и \"после\" фильтрации, сделать выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Перебрать значения гиперпараметра $k$ в каком-нибудь диапазоне с использованием кросс-валидации на данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Многоклассовая классификация:\n",
    "   - Привести описание датасета.\n",
    "   - Осуществить предобработку данных - \"подчистить данные\".\n",
    "   - Закодировать категориальные признаки при необходимости.\n",
    "   - Нормализовать данные.\n",
    "   - Выбрать какое-нибудь значение гиперпараметра $k$ алгоритма $kNN$.\n",
    "   - Разбить выборку на обучающую и тестовую.\n",
    "     > Разбиение использовать одно и то же для данных без фильтрации признаков и с применением фильтрации.\n",
    "   - Осуществить многоклассовую классификацию.\n",
    "   - Посчитать метрики: $accuracy$, $precision$, $recall$, $\\textit{f-measure}$, а также составить `classification_report`.\n",
    "   - Построить `сorrelation heatmap` и/или воспользоваться методом `corr()`. Выбрать наиболее важные признаки эвристически или на основании каких-нибудь вычислений (***см. [примечание](#примечание)***).\n",
    "   - Осуществить многоклассовую классификацию с отфильтрованными признаками.\n",
    "   - Посчитать метрики: $accuracy$, $precision$, $recall$, $\\textit{f-measure}$, а также составить `classification_report`.\n",
    "   - Сравнить результаты \"до\" и \"после\" фильтрации, сделать выводы.\n",
    "   - Перебрать значения гиперпараметра $k$ в каком-нибудь диапазоне с использованием кросс-валидации на данных\n",
    "      > данных - исходных данных до разбиения\n",
    "\n",
    "     с отфильтрованными признаками. Построить график *train/test accuracy* в зависимости от значения $k$.\n",
    "   - Для лучшего классификатора привести метрики, `classification_report`, построить [confusion matrix](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html) (это вроде матрицы $TN$ / $TP$ / $FN$ / $FP$, только расширенной для многоклассовой классификации, чтобы понять, в какие стороны чаще ошибается классификатор)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Привести описание датасета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Осуществить предобработку данных - \"подчистить данные\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Закодировать категориальные признаки при необходимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Нормализовать данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Выбрать какое-нибудь значение гиперпараметра $k$ алгоритма $kNN$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Разбить выборку на обучающую и тестовую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Осуществить многоклассовую классификацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Посчитать метрики: $accuracy$, $precision$, $recall$, $\\textit{f-measure}$, а также составить `classification_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Построить `сorrelation heatmap` и/или воспользоваться методом `corr()`. Выбрать наиболее важные признаки эвристически или на основании каких-нибудь вычислений (***см. [примечание](#примечание)***)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Осуществить многоклассовую классификацию с отфильтрованными признаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Посчитать метрики: $accuracy$, $precision$, $recall$, $\\textit{f-measure}$, а также составить `classification_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Сравнить результаты \"до\" и \"после\" фильтрации, сделать выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Перебрать значения гиперпараметра $k$ в каком-нибудь диапазоне с использованием кросс-валидации на данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Для лучшего классификатора привести метрики, `classification_report`, построить [confusion matrix](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html) (это вроде матрицы $TN$ / $TP$ / $FN$ / $FP$, только расширенной для многоклассовой классификации, чтобы понять, в какие стороны чаще ошибается классификатор)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
