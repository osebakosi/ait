{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting 6133 Тюгаев Никита Павлович"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Считать в `pandas.DataFrame` датасет automobile из ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Импортируем модели градиентного бустинга\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import catboost as cb\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "\n",
    "# Импортируем SHAP для анализа важности признаков\n",
    "import shap\n",
    "\n",
    "# Импортируем библиотеку для визуализации деревьев решений\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "# Импортируем датасет из ucimlrepo\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# Настройка отображения графиков\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "# Отключаем предупреждения\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем датасет automobile из ucimlrepo\n",
    "automobile = fetch_ucirepo(id=10)\n",
    "\n",
    "# Получаем данные и метаданные\n",
    "X = automobile.data.features\n",
    "y = automobile.data.targets\n",
    "metadata = automobile.metadata\n",
    "variable_info = automobile.variables\n",
    "\n",
    "# Объединяем признаки и целевую переменную в один датафрейм\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Выводим информацию о датасете\n",
    "print(f\"Название датасета: {metadata['name']}\")\n",
    "print(f\"Количество наблюдений: {metadata['num_instances']}\")\n",
    "print(f\"Количество признаков: {metadata['num_features']}\")\n",
    "print(f\"Целевая переменная для регрессии: price\")\n",
    "\n",
    "# Выводим первые 5 строк датафрейма\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Датасет и подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Привести описание датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выводим описание датасета\n",
    "print(metadata['abstract'])\n",
    "\n",
    "# Выводим информацию о переменных\n",
    "variable_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем общую информацию о датафрейме\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Статистическое описание числовых признаков\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Осуществить предобработку данных (избавиться от `null`, убрать некоторые признаки и т.п.) - \"подчистить данные\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем наличие пропущенных значений\n",
    "print(\"Количество пропущенных значений в каждом столбце:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Проверяем наличие значений '?' (часто используется в UCI датасетах вместо NaN)\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        if (df[col] == '?').any():\n",
    "            print(f\"Столбец {col} содержит значения '?': {(df[col] == '?').sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заменяем значения '?' на NaN\n",
    "df_clean = df.replace('?', np.nan)\n",
    "\n",
    "# Преобразуем столбцы с числовыми данными из строкового типа в числовой\n",
    "numeric_cols = ['normalized-losses', 'bore', 'stroke', 'horsepower', 'peak-rpm', 'price']\n",
    "for col in numeric_cols:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "\n",
    "# Проверяем наличие пропущенных значений после преобразования\n",
    "print(\"Количество пропущенных значений после преобразования:\")\n",
    "print(df_clean.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заменяем пропущенные значения\n",
    "categorical_cols = df_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = df_clean.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Для числовых признаков используем медиану\n",
    "for col in numerical_cols:\n",
    "    df_clean[col] = df_clean[col].fillna(df_clean[col].median())\n",
    "    \n",
    "# Для категориальных признаков используем наиболее частое значение\n",
    "for col in categorical_cols:\n",
    "    df_clean[col] = df_clean[col].fillna(df_clean[col].mode()[0])\n",
    "    \n",
    "print(f\"Размер датафрейма после заполнения пропущенных значений: {df_clean.shape}\")\n",
    "\n",
    "# Удаляем целевые переменные из списка числовых признаков\n",
    "if 'price' in numerical_cols:\n",
    "    numerical_cols.remove('price')\n",
    "\n",
    "print(\"Категориальные признаки:\")\n",
    "print(categorical_cols)\n",
    "print(\"\\nЧисловые признаки:\")\n",
    "print(numerical_cols)\n",
    "print(\"\\nЦелевая переменная для регрессии: price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Нормализовать численные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем копию датафрейма для нормализации\n",
    "df_normalized = df_clean.copy()\n",
    "\n",
    "# Создаем объект StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Нормализуем числовые признаки\n",
    "df_normalized[numerical_cols] = scaler.fit_transform(df_clean[numerical_cols])\n",
    "\n",
    "# Выводим первые 5 строк нормализованного датафрейма\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Разбить выборку на обучающую и тестовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем целевую переменную для классификации (symblings)\n",
    "# Предположим, что мы будем использовать признак 'num-of-doors' в качестве целевой переменной для классификации\n",
    "# Так как в датасете нет признака 'symblings', мы будем использовать 'num-of-doors' как аналог\n",
    "\n",
    "# Кодируем категориальную целевую переменную\n",
    "label_encoder = LabelEncoder()\n",
    "df_clean['doors_encoded'] = label_encoder.fit_transform(df_clean['num-of-doors'])\n",
    "\n",
    "# Сохраняем исходные датафреймы для дальнейшего использования\n",
    "df_original = df_clean.copy()\n",
    "\n",
    "# Разделяем данные на признаки (X) и целевые переменные (y_reg для регрессии, y_cls для классификации)\n",
    "X = df_clean.drop(['price', 'doors_encoded', 'num-of-doors'], axis=1)\n",
    "y_reg = df_clean['price']  # Целевая переменная для регрессии\n",
    "y_cls = df_clean['doors_encoded']  # Целевая переменная для классификации\n",
    "\n",
    "# Разбиваем выборку на обучающую и тестовую (80% обучающая, 20% тестовая)\n",
    "X_train, X_test, y_reg_train, y_reg_test, y_cls_train, y_cls_test = train_test_split(\n",
    "    X, y_reg, y_cls, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Размер обучающей выборки: {X_train.shape}\")\n",
    "print(f\"Размер тестовой выборки: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Формирование наборов с закодированными категориальными признаками и без обработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем препроцессор для кодирования категориальных признаков\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Применяем препроцессор к обучающей выборке\n",
    "X_train_encoded = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Применяем препроцессор к тестовой выборке\n",
    "X_test_encoded = preprocessor.transform(X_test)\n",
    "\n",
    "# Получаем имена признаков после кодирования\n",
    "encoded_features = numerical_cols.copy()\n",
    "for i, category in enumerate(categorical_cols):\n",
    "    # Получаем категории для каждого категориального признака\n",
    "    categories = preprocessor.transformers_[1][1].categories_[i]\n",
    "    # Добавляем имена закодированных признаков (исключая первую категорию из-за drop='first')\n",
    "    encoded_features.extend([f\"{category}_{cat}\" for cat in categories[1:]])\n",
    "\n",
    "print(f\"Размер обучающей выборки после кодирования: {X_train_encoded.shape}\")\n",
    "print(f\"Размер тестовой выборки после кодирования: {X_test_encoded.shape}\")\n",
    "print(f\"Количество признаков после кодирования: {len(encoded_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем категориальные признаки для CatBoost и XGBoost\n",
    "cat_features_indices = [X_train.columns.get_loc(col) for col in categorical_cols]\n",
    "print(f\"Индексы категориальных признаков: {cat_features_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Для каждого из классификаторов ($AdaBoost$, $GradientBoostingClassifier$, $XGBoost$, $CatBoost$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 $AdaBoost$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 С использованием `GridSearchCV` осуществить подбор гиперпараметра модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем сетку параметров для AdaBoost\n",
    "adaboost_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'algorithm': ['SAMME', 'SAMME.R']\n",
    "}\n",
    "\n",
    "# Создаем объект AdaBoostClassifier\n",
    "adaboost = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# Создаем объект GridSearchCV\n",
    "adaboost_grid = GridSearchCV(adaboost, adaboost_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Обучаем модель с подбором параметров\n",
    "adaboost_grid.fit(X_train_encoded, y_cls_train)\n",
    "\n",
    "# Выводим лучшие параметры\n",
    "print(f\"Лучшие параметры для AdaBoost: {adaboost_grid.best_params_}\")\n",
    "print(f\"Лучший score (accuracy): {adaboost_grid.best_score_:.4f}\")\n",
    "\n",
    "# Получаем лучшую модель\n",
    "best_adaboost = adaboost_grid.best_estimator_\n",
    "\n",
    "# Делаем предсказания на тестовой выборке\n",
    "y_pred_adaboost = best_adaboost.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Вывести метрики на тестовом наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для вычисления и вывода метрик классификации\n",
    "def evaluate_classifier(y_true, y_pred, model_name):\n",
    "    print(f\"Метрики для модели {model_name}:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1}\n",
    "\n",
    "# Вычисляем метрики для AdaBoost\n",
    "adaboost_metrics = evaluate_classifier(y_cls_test, y_pred_adaboost, \"AdaBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 $GradientBoostingClassifier$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 С использованием `GridSearchCV` осуществить подбор гиперпараметра модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем сетку параметров для GradientBoostingClassifier\n",
    "gb_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# Создаем объект GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Создаем объект GridSearchCV\n",
    "gb_grid = GridSearchCV(gb, gb_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Обучаем модель с подбором параметров\n",
    "gb_grid.fit(X_train_encoded, y_cls_train)\n",
    "\n",
    "# Выводим лучшие параметры\n",
    "print(f\"Лучшие параметры для GradientBoostingClassifier: {gb_grid.best_params_}\")\n",
    "print(f\"Лучший score (accuracy): {gb_grid.best_score_:.4f}\")\n",
    "\n",
    "# Получаем лучшую модель\n",
    "best_gb = gb_grid.best_estimator_\n",
    "\n",
    "# Делаем предсказания на тестовой выборке\n",
    "y_pred_gb = best_gb.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Вывести метрики на тестовом наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисляем метрики для GradientBoostingClassifier\n",
    "gb_metrics = evaluate_classifier(y_cls_test, y_pred_gb, \"GradientBoostingClassifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 $XGBoost$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 С использованием `GridSearchCV` осуществить подбор гиперпараметра модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем сетку параметров для XGBoost\n",
    "xgb_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 1.0],\n",
    "    'reg_lambda': [0, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "# Создаем объект XGBClassifier\n",
    "xgb_cls = XGBClassifier(random_state=42, early_stopping_rounds=10, eval_metric='mlogloss')\n",
    "\n",
    "# Создаем объект GridSearchCV\n",
    "xgb_grid = GridSearchCV(xgb_cls, xgb_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Обучаем модель с подбором параметров\n",
    "xgb_grid.fit(X_train_encoded, y_cls_train)\n",
    "\n",
    "# Выводим лучшие параметры\n",
    "print(f\"Лучшие параметры для XGBoost: {xgb_grid.best_params_}\")\n",
    "print(f\"Лучший score (accuracy): {xgb_grid.best_score_:.4f}\")\n",
    "\n",
    "# Получаем лучшую модель\n",
    "best_xgb = xgb_grid.best_estimator_\n",
    "\n",
    "# Делаем предсказания на тестовой выборке\n",
    "y_pred_xgb = best_xgb.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Обучить модель XGBoost с найденными гиперпараметрами на обучающей выборке с категориальными признаками \"как есть\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем модель XGBoost с найденными гиперпараметрами\n",
    "xgb_cat = XGBClassifier(\n",
    "    n_estimators=best_xgb.n_estimators,\n",
    "    learning_rate=best_xgb.learning_rate,\n",
    "    max_depth=best_xgb.max_depth,\n",
    "    subsample=best_xgb.subsample,\n",
    "    colsample_bytree=best_xgb.colsample_bytree,\n",
    "    reg_alpha=best_xgb.reg_alpha,\n",
    "    reg_lambda=best_xgb.reg_lambda,\n",
    "    random_state=42,\n",
    "    enable_categorical=True  # Включаем поддержку категориальных признаков\n",
    ")\n",
    "\n",
    "# Обучаем модель на данных с категориальными признаками \"как есть\"\n",
    "xgb_cat.fit(X_train, y_cls_train)\n",
    "\n",
    "# Делаем предсказания на тестовой выборке\n",
    "y_pred_xgb_cat = xgb_cat.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3 Вывести метрики на тестовом наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисляем метрики для XGBoost с закодированными признаками\n",
    "xgb_metrics = evaluate_classifier(y_cls_test, y_pred_xgb, \"XGBoost (с закодированными признаками)\")\n",
    "\n",
    "# Вычисляем метрики для XGBoost с категориальными признаками \"как есть\"\n",
    "xgb_cat_metrics = evaluate_classifier(y_cls_test, y_pred_xgb_cat, \"XGBoost (с категориальными признаками 'как есть')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 $CatBoost$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1 С использованием `grid_search` осуществить подбор гиперпараметра модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем сетку параметров для CatBoost\n",
    "catboost_params = {\n",
    "    'iterations': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'depth': [4, 6, 8],\n",
    "    'l2_leaf_reg': [1, 3, 5],\n",
    "    'border_count': [32, 64],\n",
    "    'bagging_temperature': [0, 1],\n",
    "    'random_strength': [1, 10]\n",
    "}\n",
    "\n",
    "# Создаем объект CatBoostClassifier\n",
    "catboost_cls = CatBoostClassifier(\n",
    "    random_seed=42,\n",
    "    verbose=False,\n",
    "    train_size=0.8,  # Часть обучающей выборки пойдет в валидационный набор\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "# Создаем объект GridSearchCV\n",
    "catboost_grid = GridSearchCV(catboost_cls, catboost_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Обучаем модель с подбором параметров\n",
    "catboost_grid.fit(X_train_encoded, y_cls_train)\n",
    "\n",
    "# Выводим лучшие параметры\n",
    "print(f\"Лучшие параметры для CatBoost: {catboost_grid.best_params_}\")\n",
    "print(f\"Лучший score (accuracy): {catboost_grid.best_score_:.4f}\")\n",
    "\n",
    "# Получаем лучшую модель\n",
    "best_catboost = catboost_grid.best_estimator_\n",
    "\n",
    "# Делаем предсказания на тестовой выборке\n",
    "y_pred_catboost = best_catboost.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 Обучить модель CatBoost с найденными гиперпараметрами на обучающей выборке с категориальными признаками \"как есть\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем модель CatBoost с найденными гиперпараметрами\n",
    "catboost_cat = CatBoostClassifier(\n",
    "    iterations=best_catboost.iterations,\n",
    "    learning_rate=best_catboost.learning_rate,\n",
    "    depth=best_catboost.depth,\n",
    "    l2_leaf_reg=best_catboost.l2_leaf_reg,\n",
    "    border_count=best_catboost.border_count,\n",
    "    bagging_temperature=best_catboost.bagging_temperature,\n",
    "    random_strength=best_catboost.random_strength,\n",
    "    random_seed=42,\n",
    "    verbose=False,\n",
    "    cat_features=cat_features_indices  # Указываем индексы категориальных признаков\n",
    ")\n",
    "\n",
    "# Обучаем модель на данных с категориальными признаками \"как есть\"\n",
    "catboost_cat.fit(X_train, y_cls_train)\n",
    "\n",
    "# Делаем предсказания на тестовой выборке\n",
    "y_pred_catboost_cat = catboost_cat.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.3 Вывести метрики на тестовом наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисляем метрики для CatBoost с закодированными признаками\n",
    "catboost_metrics = evaluate_classifier(y_cls_test, y_pred_catboost, \"CatBoost (с закодированными признаками)\")\n",
    "\n",
    "# Вычисляем метрики для CatBoost с категориальными признаками \"как есть\"\n",
    "catboost_cat_metrics = evaluate_classifier(y_cls_test, y_pred_catboost_cat, \"CatBoost (с категориальными признаками 'как есть')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Сравнить модели, выбрать лучшую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем датафрейм для сравнения метрик\n",
    "metrics_comparison = pd.DataFrame({\n",
    "    'Модель': ['AdaBoost', 'GradientBoostingClassifier', 'XGBoost (закодированные)', 'XGBoost (как есть)', 'CatBoost (закодированные)', 'CatBoost (как есть)'],\n",
    "    'Accuracy': [adaboost_metrics['accuracy'], gb_metrics['accuracy'], xgb_metrics['accuracy'], xgb_cat_metrics['accuracy'], catboost_metrics['accuracy'], catboost_cat_metrics['accuracy']],\n",
    "    'Precision': [adaboost_metrics['precision'], gb_metrics['precision'], xgb_metrics['precision'], xgb_cat_metrics['precision'], catboost_metrics['precision'], catboost_cat_metrics['precision']],\n",
    "    'Recall': [adaboost_metrics['recall'], gb_metrics['recall'], xgb_metrics['recall'], xgb_cat_metrics['recall'], catboost_metrics['recall'], catboost_cat_metrics['recall']],\n",
    "    'F1 Score': [adaboost_metrics['f1'], gb_metrics['f1'], xgb_metrics['f1'], xgb_cat_metrics['f1'], catboost_metrics['f1'], catboost_cat_metrics['f1']]\n",
    "})\n",
    "\n",
    "# Сортируем по убыванию F1 Score\n",
    "metrics_comparison = metrics_comparison.sort_values('F1 Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Выводим сравнение метрик\n",
    "metrics_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем лучшую модель на основе F1 Score\n",
    "best_model_name = metrics_comparison.iloc[0]['Модель']\n",
    "print(f\"Лучшая модель: {best_model_name}\")\n",
    "\n",
    "# Выбираем лучшую модель для дальнейшего анализа\n",
    "if best_model_name == 'CatBoost (как есть)':\n",
    "    best_model = catboost_cat\n",
    "elif best_model_name == 'CatBoost (закодированные)':\n",
    "    best_model = best_catboost\n",
    "elif best_model_name == 'XGBoost (как есть)':\n",
    "    best_model = xgb_cat\n",
    "elif best_model_name == 'XGBoost (закодированные)':\n",
    "    best_model = best_xgb\n",
    "elif best_model_name == 'GradientBoostingClassifier':\n",
    "    best_model = best_gb\n",
    "else:  # AdaBoost\n",
    "    best_model = best_adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Важность признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 С использованием `shap.TreeExplainer` получить $SHAP$-значения для лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем, какие данные использовать для SHAP в зависимости от лучшей модели\n",
    "if 'как есть' in best_model_name:\n",
    "    X_shap = X_test\n",
    "    feature_names = X_test.columns\n",
    "else:\n",
    "    X_shap = X_test_encoded\n",
    "    feature_names = encoded_features\n",
    "\n",
    "# Создаем SHAP explainer\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "\n",
    "# Вычисляем SHAP значения\n",
    "shap_values = explainer.shap_values(X_shap)\n",
    "\n",
    "# Если shap_values - это список (для мультиклассовой классификации), берем первый класс\n",
    "if isinstance(shap_values, list):\n",
    "    print(f\"SHAP значения для {len(shap_values)} классов\")\n",
    "    # Для визуализации будем использовать значения для первого класса\n",
    "    shap_values_class0 = shap_values[0]\n",
    "else:\n",
    "    print(\"SHAP значения для бинарной классификации или регрессии\")\n",
    "    shap_values_class0 = shap_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Построить график `shap.plots.force` для одного объекта выборки и для среза произвольного размера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для одного объекта выборки\n",
    "shap.plots.force(explainer.expected_value[0] if isinstance(explainer.expected_value, list) else explainer.expected_value, \n",
    "                 shap_values_class0[0], \n",
    "                 X_shap.iloc[0], \n",
    "                 feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для среза произвольного размера (первые 5 объектов)\n",
    "shap.plots.force(explainer.expected_value[0] if isinstance(explainer.expected_value, list) else explainer.expected_value, \n",
    "                 shap_values_class0[:5], \n",
    "                 X_shap.iloc[:5], \n",
    "                 feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Построить график `shap.plots.bar` для одного объекта выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем объект Explanation для одного объекта\n",
    "exp = shap.Explanation(values=shap_values_class0[0], \n",
    "                       base_values=explainer.expected_value[0] if isinstance(explainer.expected_value, list) else explainer.expected_value,\n",
    "                       data=X_shap.iloc[0].values,\n",
    "                       feature_names=feature_names)\n",
    "\n",
    "# Строим bar plot для одного объекта\n",
    "shap.plots.bar(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Построить график `shap.plots.waterfall` для одного объекта выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Строим waterfall plot для одного объекта\n",
    "shap.plots.waterfall(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Построить 2 графика `shap.plots.scatter` для какого-нибудь признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем индекс признака для анализа (например, первый числовой признак)\n",
    "feature_idx = 0\n",
    "\n",
    "# График 1: Раскраска относительно самого признака\n",
    "shap.plots.scatter(shap_values_class0[:, feature_idx], color=X_shap.iloc[:, feature_idx], \n",
    "                   feature_names=[feature_names[feature_idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# График 2: Раскраска относительно другого признака (например, второго числового признака)\n",
    "other_feature_idx = 1\n",
    "shap.plots.scatter(shap_values_class0[:, feature_idx], color=X_shap.iloc[:, other_feature_idx], \n",
    "                   feature_names=[feature_names[feature_idx]], color_bar_label=feature_names[other_feature_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Построить график `shap.plots.beeswarm` для всех признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Строим beeswarm plot для всех признаков\n",
    "shap.plots.beeswarm(shap.Explanation(values=shap_values_class0, \n",
    "                                    base_values=explainer.expected_value[0] if isinstance(explainer.expected_value, list) else explainer.expected_value,\n",
    "                                    data=X_shap.values,\n",
    "                                    feature_names=feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Построить график `shap.plots.bar` для всех признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Строим bar plot для всех признаков (средние абсолютные значения SHAP)\n",
    "shap.plots.bar(shap.Explanation(values=shap_values_class0, \n",
    "                               base_values=explainer.expected_value[0] if isinstance(explainer.expected_value, list) else explainer.expected_value,\n",
    "                               data=X_shap.values,\n",
    "                               feature_names=feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 На основании двух последних графиков и/или используя `feature_importance` отфильровать признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем важность признаков из SHAP значений\n",
    "feature_importance = np.abs(shap_values_class0).mean(axis=0)\n",
    "\n",
    "# Создаем датафрейм с важностью признаков\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "importance_df = importance_df.sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Выводим важность признаков\n",
    "importance_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируем важность признаков\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(importance_df['Feature'][:15], importance_df['Importance'][:15])\n",
    "plt.xlabel('Средняя абсолютная величина SHAP')\n",
    "plt.ylabel('Признак')\n",
    "plt.title('Топ-15 признаков по важности')\n",
    "plt.gca().invert_yaxis()  # Инвертируем ось Y для отображения самых важных признаков сверху\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем порог важности (например, берем 50% самых важных признаков)\n",
    "n_features_to_keep = len(feature_names) // 2\n",
    "important_features = importance_df['Feature'][:n_features_to_keep].values\n",
    "\n",
    "print(f\"Количество отобранных признаков: {len(important_features)}\")\n",
    "print(\"Отобранные признаки:\")\n",
    "print(important_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9 Переобучить лучшую модель на отфильтрованных признаках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фильтруем данные, оставляя только важные признаки\n",
    "if 'как есть' in best_model_name:\n",
    "    # Для моделей с категориальными признаками \"как есть\"\n",
    "    important_indices = [list(X_train.columns).index(feat) for feat in important_features if feat in X_train.columns]\n",
    "    X_train_filtered = X_train.iloc[:, important_indices]\n",
    "    X_test_filtered = X_test.iloc[:, important_indices]\n",
    "    \n",
    "    # Обновляем индексы категориальных признаков\n",
    "    cat_features_filtered = []\n",
    "    for i, feat in enumerate(X_train_filtered.columns):\n",
    "        if feat in categorical_cols:\n",
    "            cat_features_filtered.append(i)\n",
    "else:\n",
    "    # Для моделей с закодированными признаками\n",
    "    important_indices = [list(encoded_features).index(feat) for feat in important_features if feat in encoded_features]\n",
    "    X_train_filtered = X_train_encoded[:, important_indices]\n",
    "    X_test_filtered = X_test_encoded[:, important_indices]\n",
    "    cat_features_filtered = []\n",
    "\n",
    "print(f\"Размер отфильтрованной обучающей выборки: {X_train_filtered.shape}\")\n",
    "print(f\"Размер отфильтрованной тестовой выборки: {X_test_filtered.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переобучаем лучшую модель на отфильтрованных признаках\n",
    "if 'CatBoost (как есть)' in best_model_name:\n",
    "    filtered_model = CatBoostClassifier(\n",
    "        iterations=best_catboost.iterations,\n",
    "        learning_rate=best_catboost.learning_rate,\n",
    "        depth=best_catboost.depth,\n",
    "        l2_leaf_reg=best_catboost.l2_leaf_reg,\n",
    "        border_count=best_catboost.border_count,\n",
    "        bagging_temperature=best_catboost.bagging_temperature,\n",
    "        random_strength=best_catboost.random_strength,\n",
    "        random_seed=42,\n",
    "        verbose=False,\n",
    "        cat_features=cat_features_filtered\n",
    "    )\n",
    "elif 'CatBoost (закодированные)' in best_model_name:\n",
    "    filtered_model = CatBoostClassifier(\n",
    "        iterations=best_catboost.iterations,\n",
    "        learning_rate=best_catboost.learning_rate,\n",
    "        depth=best_catboost.depth,\n",
    "        l2_leaf_reg=best_catboost.l2_leaf_reg,\n",
    "        border_count=best_catboost.border_count,\n",
    "        bagging_temperature=best_catboost.bagging_temperature,\n",
    "        random_strength=best_catboost.random_strength,\n",
    "        random_seed=42,\n",
    "        verbose=False\n",
    "    )\n",
    "elif 'XGBoost (как есть)' in best_model_name:\n",
    "    filtered_model = XGBClassifier(\n",
    "        n_estimators=best_xgb.n_estimators,\n",
    "        learning_rate=best_xgb.learning_rate,\n",
    "        max_depth=best_xgb.max_depth,\n",
    "        subsample=best_xgb.subsample,\n",
    "        colsample_bytree=best_xgb.colsample_bytree,\n",
    "        reg_alpha=best_xgb.reg_alpha,\n",
    "        reg_lambda=best_xgb.reg_lambda,\n",
    "        random_state=42,\n",
    "        enable_categorical=True\n",
    "    )\n",
    "elif 'XGBoost (закодированные)' in best_model_name:\n",
    "    filtered_model = XGBClassifier(\n",
    "        n_estimators=best_xgb.n_estimators,\n",
    "        learning_rate=best_xgb.learning_rate,\n",
    "        max_depth=best_xgb.max_depth,\n",
    "        subsample=best_xgb.subsample,\n",
    "        colsample_bytree=best_xgb.colsample_bytree,\n",
    "        reg_alpha=best_xgb.reg_alpha,\n",
    "        reg_lambda=best_xgb.reg_lambda,\n",
    "        random_state=42\n",
    "    )\n",
    "elif 'GradientBoostingClassifier' in best_model_name:\n",
    "    filtered_model = GradientBoostingClassifier(\n",
    "        n_estimators=best_gb.n_estimators,\n",
    "        learning_rate=best_gb.learning_rate,\n",
    "        max_depth=best_gb.max_depth,\n",
    "        subsample=best_gb.subsample,\n",
    "        min_samples_split=best_gb.min_samples_split,\n",
    "        random_state=42\n",
    "    )\n",
    "else:  # AdaBoost\n",
    "    filtered_model = AdaBoostClassifier(\n",
    "        n_estimators=best_adaboost.n_estimators,\n",
    "        learning_rate=best_adaboost.learning_rate,\n",
    "        algorithm=best_adaboost.algorithm,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "# Обучаем модель на отфильтрованных признаках\n",
    "filtered_model.fit(X_train_filtered, y_cls_train)\n",
    "\n",
    "# Делаем предсказания на тестовой выборке\n",
    "y_pred_filtered = filtered_model.predict(X_test_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.10 Сравнить метрики до и после фильтрации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисляем метрики для модели с отфильтрованными признаками\n",
    "filtered_metrics = evaluate_classifier(y_cls_test, y_pred_filtered, f\"{best_model_name} (с отфильтрованными признаками)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравниваем метрики до и после фильтрации\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Метрика': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'До фильтрации': [metrics_comparison.iloc[0]['Accuracy'], metrics_comparison.iloc[0]['Precision'], \n",
    "                     metrics_comparison.iloc[0]['Recall'], metrics_comparison.iloc[0]['F1 Score']],\n",
    "    'После фильтрации': [filtered_metrics['accuracy'], filtered_metrics['precision'], \n",
    "                        filtered_metrics['recall'], filtered_metrics['f1']],\n",
    "    'Изменение': [filtered_metrics['accuracy'] - metrics_comparison.iloc[0]['Accuracy'], \n",
    "                 filtered_metrics['precision'] - metrics_comparison.iloc[0]['Precision'],\n",
    "                 filtered_metrics['recall'] - metrics_comparison.iloc[0]['Recall'],\n",
    "                 filtered_metrics['f1'] - metrics_comparison.iloc[0]['F1 Score']]\n",
    "})\n",
    "\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.11 Визуализировать полученное дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация дерева решений зависит от типа модели\n",
    "if 'CatBoost' in best_model_name:\n",
    "    # Для CatBoost можно визуализировать одно из деревьев\n",
    "    tree_idx = 0  # Индекс дерева для визуализации\n",
    "    filtered_model.plot_tree(tree_idx=tree_idx)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.show()\n",
    "elif 'XGBoost' in best_model_name:\n",
    "    # Для XGBoost можно использовать plot_tree\n",
    "    xgb.plot_tree(filtered_model, num_trees=0)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.show()\n",
    "elif 'GradientBoostingClassifier' in best_model_name:\n",
    "    # Для GradientBoostingClassifier можно визуализировать одно из деревьев\n",
    "    tree_idx = 0  # Индекс дерева для визуализации\n",
    "    estimator = filtered_model.estimators_[tree_idx, 0]\n",
    "    \n",
    "    # Определяем имена признаков для визуализации\n",
    "    if 'как есть' in best_model_name:\n",
    "        feature_names_viz = X_train_filtered.columns\n",
    "    else:\n",
    "        feature_names_viz = important_features\n",
    "    \n",
    "    # Экспортируем дерево в формат DOT\n",
    "    dot_data = export_graphviz(\n",
    "        estimator,\n",
    "        out_file=None,\n",
    "        feature_names=feature_names_viz,\n",
    "        filled=True,\n",
    "        rounded=True,\n",
    "        special_characters=True\n",
    "    )\n",
    "    \n",
    "    # Визуализируем дерево\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 С использованием `GridSearchCV`/`grid_search` осуществить подбор гиперпараметра модели линейной регрессии с использованием $XGBoost$ или $CatBoost$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем, какую модель использовать для регрессии (XGBoost или CatBoost)\n",
    "# Выберем ту, которая показала лучшие результаты в классификации\n",
    "if 'CatBoost' in best_model_name:\n",
    "    # Определяем сетку параметров для CatBoostRegressor\n",
    "    reg_params = {\n",
    "        'iterations': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'depth': [4, 6, 8],\n",
    "        'l2_leaf_reg': [1, 3, 5],\n",
    "        'border_count': [32, 64],\n",
    "        'bagging_temperature': [0, 1],\n",
    "        'random_strength': [1, 10]\n",
    "    }\n",
    "    \n",
    "    # Создаем объект CatBoostRegressor\n",
    "    reg_model = CatBoostRegressor(\n",
    "        random_seed=42,\n",
    "        verbose=False,\n",
    "        train_size=0.8,  # Часть обучающей выборки пойдет в валидационный набор\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    \n",
    "    model_name = \"CatBoostRegressor\"\n",
    "else:\n",
    "    # Определяем сетку параметров для XGBRegressor\n",
    "    reg_params = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0],\n",
    "        'reg_alpha': [0, 0.1, 1.0],\n",
    "        'reg_lambda': [0, 0.1, 1.0]\n",
    "    }\n",
    "    \n",
    "    # Создаем объект XGBRegressor\n",
    "    reg_model = XGBRegressor(\n",
    "        random_state=42,\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    \n",
    "    model_name = \"XGBRegressor\"\n",
    "\n",
    "# Создаем объект GridSearchCV\n",
    "reg_grid = GridSearchCV(reg_model, reg_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Обучаем модель с подбором параметров\n",
    "if 'как есть' in best_model_name and model_name == \"CatBoostRegressor\":\n",
    "    # Для CatBoost с категориальными признаками \"как есть\"\n",
    "    reg_grid.fit(X_train, y_reg_train, cat_features=cat_features_indices)\n",
    "else:\n",
    "    # Для остальных случаев\n",
    "    reg_grid.fit(X_train_encoded, y_reg_train)\n",
    "\n",
    "# Выводим лучшие параметры\n",
    "print(f\"Лучшие параметры для {model_name}: {reg_grid.best_params_}\")\n",
    "print(f\"Лучший score (отрицательный MSE): {reg_grid.best_score_:.2f}\")\n",
    "\n",
    "# Получаем лучшую модель\n",
    "best_reg_model = reg_grid.best_estimator_\n",
    "\n",
    "# Делаем предсказания на тестовой выборке\n",
    "if 'как есть' in best_model_name and model_name == \"CatBoostRegressor\":\n",
    "    y_pred_reg = best_reg_model.predict(X_test)\n",
    "else:\n",
    "    y_pred_reg = best_reg_model.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Вывести метрики $MSE$, $MAE$ и $R^2$ на тестовом наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для вычисления и вывода метрик регрессии\n",
    "def evaluate_regressor(y_true, y_pred, model_name):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"Метрики для модели {model_name}:\")\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"R^2: {r2:.4f}\")\n",
    "    \n",
    "    return {'mse': mse, 'mae': mae, 'r2': r2}\n",
    "\n",
    "# Вычисляем метрики для регрессионной модели\n",
    "reg_metrics = evaluate_regressor(y_reg_test, y_pred_reg, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Переобучить модель на отфильтрованном наборе признаков из пункта 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переобучаем регрессионную модель на отфильтрованных признаках\n",
    "if model_name == \"CatBoostRegressor\":\n",
    "    reg_filtered_model = CatBoostRegressor(\n",
    "        iterations=best_reg_model.iterations,\n",
    "        learning_rate=best_reg_model.learning_rate,\n",
    "        depth=best_reg_model.depth,\n",
    "        l2_leaf_reg=best_reg_model.l2_leaf_reg,\n",
    "        border_count=best_reg_model.border_count,\n",
    "        bagging_temperature=best_reg_model.bagging_temperature,\n",
    "        random_strength=best_reg_model.random_strength,\n",
    "        random_seed=42,\n",
    "        verbose=False,\n",
    "        cat_features=cat_features_filtered if 'как есть' in best_model_name else None\n",
    "    )\n",
    "else:  # XGBRegressor\n",
    "    reg_filtered_model = XGBRegressor(\n",
    "        n_estimators=best_reg_model.n_estimators,\n",
    "        learning_rate=best_reg_model.learning_rate,\n",
    "        max_depth=best_reg_model.max_depth,\n",
    "        subsample=best_reg_model.subsample,\n",
    "        colsample_bytree=best_reg_model.colsample_bytree,\n",
    "        reg_alpha=best_reg_model.reg_alpha,\n",
    "        reg_lambda=best_reg_model.reg_lambda,\n",
    "        random_state=42,\n",
    "        enable_categorical=True if 'как есть' in best_model_name else False\n",
    "    )\n",
    "\n",
    "# Обучаем модель на отфильтрованных признаках\n",
    "reg_filtered_model.fit(X_train_filtered, y_reg_train)\n",
    "\n",
    "# Делаем предсказания на тестовой выборке\n",
    "y_pred_reg_filtered = reg_filtered_model.predict(X_test_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Сравнить метрики до и после фильтрации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисляем метрики для регрессионной модели с отфильтрованными признаками\n",
    "reg_filtered_metrics = evaluate_regressor(y_reg_test, y_pred_reg_filtered, f\"{model_name} (с отфильтрованными признаками)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравниваем метрики до и после фильтрации\n",
    "reg_comparison_df = pd.DataFrame({\n",
    "    'Метрика': ['MSE', 'MAE', 'R^2'],\n",
    "    'До фильтрации': [reg_metrics['mse'], reg_metrics['mae'], reg_metrics['r2']],\n",
    "    'После фильтрации': [reg_filtered_metrics['mse'], reg_filtered_metrics['mae'], reg_filtered_metrics['r2']],\n",
    "    'Изменение': [reg_filtered_metrics['mse'] - reg_metrics['mse'], \n",
    "                 reg_filtered_metrics['mae'] - reg_metrics['mae'],\n",
    "                 reg_filtered_metrics['r2'] - reg_metrics['r2']]\n",
    "})\n",
    "\n",
    "reg_comparison_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
